{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f7cf08-ed8d-4447-9b58-928e633b2665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "#from itertools import product\n",
    "from pynwb import NWBHDF5IO\n",
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27df6b7-751e-400a-affa-a139bb38d935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping Position_Cursor due to timestamp mismatch.\n",
      "Dropping Position_Eye due to timestamp mismatch.\n",
      "Dropping Position_Hand due to timestamp mismatch.\n",
      "Spikes found outside of observed interval.\n",
      "Dropping Position_Cursor due to timestamp mismatch.\n",
      "Dropping Position_Eye due to timestamp mismatch.\n",
      "Dropping Position_Hand due to timestamp mismatch.\n",
      "Spikes found outside of observed interval.\n",
      "Dropping Position_Cursor due to timestamp mismatch.\n",
      "Dropping Position_Eye due to timestamp mismatch.\n",
      "Dropping Position_Hand due to timestamp mismatch.\n",
      "Spikes found outside of observed interval.\n"
     ]
    }
   ],
   "source": [
    "# 'dandi download' downloads the data in this folder:\n",
    "datapath = 'data/NWB/000070/sub-Jenkins/'\n",
    "dataset = NWBDataset(datapath, split_heldout=False)\n",
    "\n",
    "# Extract neural data and lagged hand velocity.\n",
    "#binsize = 5 #ms\n",
    "#dataset.resample(binsize)\n",
    "\n",
    "trial_info = dataset.trial_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9275fcf-8631-4cba-84b4-73b6aba4862c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Combining the number of columns in the 'spikes' field with those in the 'heldout_spikes' field gives the total number of neurons.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m n_null_trials \u001b[38;5;241m=\u001b[39m trial_info\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m n_neurons \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mspikes\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mheldout_spikes\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of neurons: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neurons\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trial_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Combining the number of columns in the 'spikes' field with those in the 'heldout_spikes' field gives the total number of neurons.\n",
    "\n",
    "n_null_trials = trial_info.isnull().sum()['success']\n",
    "n_neurons = dataset.data.spikes.values.shape[1] + dataset.data.heldout_spikes.values.shape[1]\n",
    "\n",
    "print(f'number of neurons: {n_neurons}')\n",
    "print(f'total number of trials: {len(trial_info)}')\n",
    "print(f'number of null trials: {n_null_trials}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71012187-54c0-4897-8316-305e4f5ec6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trial_info\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trial_info' is not defined"
     ]
    }
   ],
   "source": [
    "trial_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe73fd8-dcec-48a6-a2c6-5ec0ab3362c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in trial_info.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70e858-d969-40e8-964b-11912b0e140f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note that there is a number of trials at the begining of the session(s) that has no metadata at all.\n",
    "# The NWBDataset function: make_trial_data() drops all of those.\n",
    "\n",
    "print(f\"Total num of trials: {len(trial_info)}\\n\")\n",
    "print(\"Count of null values in each column:\\n\")\n",
    "\n",
    "trial_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d709b-e6a0-4530-a713-7b7700c45e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of all time bins in the entire dataset.\n",
    "# That's right, each row is the measures in one time bin.\n",
    "# Also, the original sampling rate is 100Hz (10ms bin size).\n",
    "# Keep in mind that not all the trials are the same length.\n",
    "\n",
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b07bb-fea2-40d9-bd13-ab2d44ff0f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The make_trial_data() returns a DataFrame containing trialized data. It has the same fields as the continuous `dataset.data` DataFrame,\n",
    "# But adds `trial_id`, `trial_time`, and `align_time`. Till here, each row is still a time bin.\n",
    "# Note: Later we do the cropping and alignment arount move_onset by ourselves.\n",
    "\n",
    "trial_data = dataset.make_trial_data()\n",
    "len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724118c-1fe1-490e-9f16-7d0ef6a6deef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461abb03-0ead-4714-b1a1-c298cb44ffd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_info[trial_info['success'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75767e0-e45e-461c-bd10-211663bd485c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_info['active_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2f166-707f-443d-ac03-a34815b93db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(trial_data['spikes'].to_numpy().flatten()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95cfb8c-6333-4a9e-9bdc-b072bca0509d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_lens = []\n",
    "\n",
    "for trial_id, trial in trial_data.groupby('trial_id'):\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    trial_lens.append((trial.trial_time.values[-1] / np.timedelta64(1, 's')) - (trial.trial_time.values[0] / np.timedelta64(1, 's')))\n",
    "    \n",
    "plt.hist(trial_lens, bins='auto', density=False, alpha=0.7, edgecolor='gray')\n",
    "\n",
    "plt.title('trial length\\n')\n",
    "plt.xlabel('time interval of trial length (sec)')\n",
    "plt.savefig('output_figs/tl.png')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946969e2-7f89-478f-8cd7-3051027c4b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials = [trial[1] for trial in trial_data.groupby('trial_id')]\n",
    "inter_trial_intervals = []\n",
    "    \n",
    "for i, trial in enumerate(trials):\n",
    "    trial_id = i + n_null_trials - 1\n",
    "    trial_id_next = i + 1 + n_null_trials - 1\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    trial_id_trial_info_next = trial_info[trial_info['trial_id'] == trial_id_next]\n",
    "    \n",
    "    inter_trial_intervals.append((trial_id_trial_info_next['start_time'].iloc[0] / np.timedelta64(1, 's')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 's')))\n",
    "    \n",
    "plt.hist(inter_trial_intervals, bins='auto', density=False, alpha=0.7, edgecolor='gray')\n",
    "\n",
    "plt.title('inter-trial time interval\\n')\n",
    "plt.xlabel('inter-trial time interval (sec)')\n",
    "plt.savefig('output_figs/iit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd2e5c-0a80-426c-aa1e-5cc57a0995a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f41642-4290-4576-bbee-e64939f3721b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_utill_move = []\n",
    "\n",
    "for i, _ in enumerate(trials):\n",
    "    trial_id = i + n_null_trials\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    time_utill_move.append((trial_id_trial_info['move_onset_time'].iloc[0] / np.timedelta64(1, 's')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 's')))\n",
    "    \n",
    "plt.hist(time_utill_move, bins='auto', density=False, alpha=0.7, edgecolor='gray')\n",
    "plt.title('time untill movement\\n')\n",
    "plt.xlabel('time interval before move_onset (sec)')\n",
    "plt.savefig('output_figs/tibm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75989ff0-a894-45e3-8692-8e02ca94cccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_after_move = []\n",
    "\n",
    "for i, _ in enumerate(trials):\n",
    "    trial_id = i + n_null_trials\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    time_after_move.append((trial_id_trial_info['end_time'].iloc[0] / np.timedelta64(1, 's')) - (trial_id_trial_info['move_onset_time'].iloc[0] / np.timedelta64(1, 's')))\n",
    "    \n",
    "plt.hist(time_after_move, bins='auto', density=False, alpha=0.7, edgecolor='gray')\n",
    "plt.title('time after movement\\n')\n",
    "plt.xlabel('time interval after move_onset (sec)')\n",
    "plt.savefig('output_figs/tiam.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f94ee0-9b11-4966-8ea4-7d5d882339e3",
   "metadata": {},
   "source": [
    "### Forming conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3ba83-c05c-4808-9744-0806683e5fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_simple_cond(angle):\n",
    "        \n",
    "    if 350 <= angle < 360 or 0 <= angle < 38:\n",
    "        return 0\n",
    "    elif 38 <= angle < 125:\n",
    "        return 1\n",
    "    elif 125 <= angle < 175:\n",
    "        return 2\n",
    "    elif 175 <= angle < 212:\n",
    "        return 3\n",
    "    elif 212 <= angle < 232:\n",
    "        return 4\n",
    "    elif 232 <= angle < 280:\n",
    "        return 5\n",
    "    elif 280 <= angle <= 329:\n",
    "        return 6\n",
    "    elif 329 <= angle <= 350:\n",
    "        return 7\n",
    "    else:\n",
    "        raise ValueError(\"Angle out of range\")\n",
    "\n",
    "def n_unigue_conds(trial_conds):\n",
    "    # Convert each list to a frozenset and use a set to track unique frozensets\n",
    "    unique_conds = set(frozenset(cond) for cond in trial_conds)\n",
    "    return len(unique_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e909af9-d248-45c6-baf3-b56a62b2f52f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot trial-averaged reaches\n",
    "\n",
    "# Find unique conditions\n",
    "conds = trial_info.set_index(['trial_type', 'trial_version']).index.unique().tolist()\n",
    "conds = [cond for cond in conds if not any(math.isnan(x) for x in cond)]\n",
    "\n",
    "# Initialize plot\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "# Loop over conditions and compute average trajectory\n",
    "for cond in conds:\n",
    "    # Find trials in condition\n",
    "    mask = np.all(trial_info[['trial_type', 'trial_version']] == cond, axis=1)\n",
    "    # Extract trial data\n",
    "    trial_d = dataset.make_trial_data(ignored_trials=(~mask))\n",
    "    # Average hand position across trials\n",
    "    traj = trial_d.groupby('align_time')[[('hand_pos', 'x'), ('hand_pos', 'y')]].mean().to_numpy()\n",
    "    # Determine reach angle for color\n",
    "    active_target = trial_info[mask].target_pos.iloc[0][int(dataset.trial_info[mask].active_target.iloc[0])]\n",
    "    reach_angle = np.arctan2(*active_target[::-1])\n",
    "    # Plot reach\n",
    "    ax.plot([0, traj[:, 0][-1]], [0, traj[:, 1][-1]], linewidth=0.7, color=plt.cm.hsv(reach_angle / (2*np.pi) + 0.5))\n",
    "\n",
    "angle_radians = np.radians(350)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "'''\n",
    "angle_radians = np.radians(16)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "'''\n",
    "angle_radians = np.radians(38)\n",
    "x_end = 80 * np.cos(angle_radians)\n",
    "y_end = 80 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(125)\n",
    "x_end = 50 * np.cos(angle_radians)\n",
    "y_end = 50 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(175)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "'''\n",
    "angle_radians = np.radians(193)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "'''\n",
    "angle_radians = np.radians(212)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(232)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(280)\n",
    "x_end = 100 * np.cos(angle_radians)\n",
    "y_end = 100 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(329)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=0.7, color='black')\n",
    "\n",
    "angle_radians = np.radians(0)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=1.7, color='navy')\n",
    "\n",
    "angle_radians = np.radians(90)\n",
    "x_end = 50 * np.cos(angle_radians)\n",
    "y_end = 50 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=1.7, color='navy')\n",
    "\n",
    "angle_radians = np.radians(180)\n",
    "x_end = 140 * np.cos(angle_radians)\n",
    "y_end = 140 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=1.7, color='navy')\n",
    "\n",
    "angle_radians = np.radians(270)\n",
    "x_end = 100 * np.cos(angle_radians)\n",
    "y_end = 100 * np.sin(angle_radians)\n",
    "ax.plot([0, x_end], [0, y_end], linewidth=1.7, color='navy')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4e9dd-d340-4586-b3bf-b5301cc2be5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot trial-averaged reaches\n",
    "\n",
    "# Find unique conditions\n",
    "maze_conds = trial_info.set_index(['trial_type', 'trial_version']).index.unique().tolist()\n",
    "maze_conds = [cond for cond in maze_conds if not any(math.isnan(x) for x in cond)]\n",
    "\n",
    "orig_conds = {}\n",
    "simp_conds = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[]}\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.suptitle('Aligned trials (same length)')\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "# Loop over conditions and compute average trajectory\n",
    "for cond_idx, cond in enumerate(maze_conds):\n",
    "    # Find trials in condition\n",
    "    mask = np.all(dataset.trial_info[['trial_type', 'trial_version']] == cond, axis=1)\n",
    "    trial_d = dataset.make_trial_data(align_field='move_onset_time', align_range=(-240, 660), ignored_trials=(~mask))\n",
    "    traj = trial_d.groupby('align_time')[[('hand_pos', 'x'), ('hand_pos', 'y')]].mean().to_numpy()\n",
    "    # Determine reach angle for color\n",
    "    reach_angle = np.arctan2(*trial_info[mask].target_pos.iloc[0][int(trial_info[mask].active_target.iloc[0])][::-1])\n",
    "    # Plot reach\n",
    "    ax.plot(traj[:, 0], traj[:, 1], linewidth=0.7, color=plt.cm.hsv(reach_angle / (2*np.pi) + 0.5))\n",
    "    \n",
    "    orig_conds[cond_idx] = trial_d.trial_id.drop_duplicates().values\n",
    "    simp_conds[get_simple_cond(math.degrees(reach_angle) + 360 / 2)].append(trial_d.trial_id.drop_duplicates().values)\n",
    "\n",
    "simp_conds = {key: np.concatenate(value) for key, value in simp_conds.items()}\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b8112-0ca1-4eba-98ca-aa3139941ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conds = []\n",
    "for trial_id, trial in trial_data.groupby('trial_id'):\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    for cond, trial_ids in orig_conds.items():\n",
    "        if trial_id in trial_ids:\n",
    "            conds.append(cond)\n",
    "            break\n",
    "            \n",
    "maze_conds = torch.tensor(maze_conds)\n",
    "conds = torch.tensor(conds)\n",
    "\n",
    "print(maze_conds.shape)\n",
    "print(conds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4f442-611c-478b-a935-7c64971e2cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, cond_counts = torch.unique(conds, return_counts=True)\n",
    "cond_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8c43f-77d3-4aa5-b23e-b93dea9ae6a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Forming trials and label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2ac98-41c3-4de7-b3f1-1dae048b36b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[col for col in trial_data.columns if any(_ in col for _ in ['vel', 'pos', 'force', 'acc', 'target'])]\n",
    "label_cols = [col for col in trial_data.columns if any(_ in col for _ in ['x', 'y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a76fb4-6d1d-4a6e-a8d9-f557d4f6b5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f328b7-6857-427f-bdca-fb12af8d23f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Align the trials arount the move_onset bin with offsets before and after that bin.\n",
    "y = []\n",
    "labels = []\n",
    "target_pos = []\n",
    "active_target = []\n",
    "conds = []\n",
    "\n",
    "# We want total trial length of 900ms, which is 90 time bins.\n",
    "bins_before_move = 48\n",
    "bins_after_move = 132\n",
    "\n",
    "trial_length = bins_before_move + bins_after_move\n",
    "n_trials = trial_data.shape[0] // trial_length\n",
    "\n",
    "for trial_id, trial in trial_data.groupby('trial_id'):\n",
    "    trial_id_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "            \n",
    "    # Get the untill movement in ms.\n",
    "    move_time = (trial_id_info['move_onset_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))\n",
    "    # Get the number of bins until movement.\n",
    "    move_bin = int(move_time // binsize)\n",
    "\n",
    "    y_heldin_t = torch.tensor(trial.spikes.values)\n",
    "    y_heldout_t = torch.tensor(trial.heldout_spikes.values)\n",
    "    \n",
    "    # Crop the trials arount the move_onset bin with offsets before and after that bin.\n",
    "    y_t = torch.concat(\n",
    "        [y_heldin_t[move_bin-bins_before_move:move_bin+bins_after_move, :], y_heldout_t[move_bin-bins_before_move:move_bin+bins_after_move, :]], dim=-1\n",
    "    )\n",
    "    \n",
    "    y.append(y_t.reshape(1, trial_length, n_neurons))\n",
    "    labels.append(torch.tensor(trial.cursor_pos.values[move_bin-bins_before_move:move_bin+bins_after_move, :]).reshape(1, trial_length, 2))\n",
    "    \n",
    "    target_pos.append(trial_id_info.target_pos.values[0])\n",
    "    active_target.append(int(trial_id_info.active_target.values[0]))\n",
    "    \n",
    "    for cond, trial_ids in orig_conds.items():\n",
    "        if trial_id in trial_ids:\n",
    "            conds.append(cond)\n",
    "    \n",
    "y = torch.concat(y, dim=0)\n",
    "labels = torch.concat(labels, dim=0)\n",
    "conds = torch.tensor(conds)\n",
    "active_target = torch.tensor(active_target)\n",
    "\n",
    "print(y.shape)\n",
    "print(labels.shape)\n",
    "print(conds.shape)\n",
    "print(len(target_pos))\n",
    "print(active_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bc4f2-8817-4a0a-a3d7-25faafe57710",
   "metadata": {},
   "source": [
    "### Forming events occurance time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188f9a0-33ed-46be-92ad-529916dc08b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, _ in enumerate(trials):\n",
    "    trial_id = i + n_null_trials\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    target_on = (((trial_id_trial_info['target_on_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    gocue = (((trial_id_trial_info['go_cue_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    move_onset = (((trial_id_trial_info['move_onset_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1653d-f08c-4e7f-ab2a-0afa535bc469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_bins = []\n",
    "gocue_bins = []\n",
    "move_bins = []\n",
    "event_bins = []\n",
    "\n",
    "for i, _ in enumerate(trials):\n",
    "    trial_id = i + n_null_trials\n",
    "    trial_id_trial_info = trial_info[trial_info['trial_id'] == trial_id]\n",
    "    \n",
    "    # target : go\n",
    "    delay = (((trial_id_trial_info['go_cue_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['target_on_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    # go : move\n",
    "    prep = (((trial_id_trial_info['move_onset_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['go_cue_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    \n",
    "    target_on = (((trial_id_trial_info['target_on_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    gocue = (((trial_id_trial_info['go_cue_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    move_onset = (((trial_id_trial_info['move_onset_time'].iloc[0] / np.timedelta64(1, 'ms')) - (trial_id_trial_info['start_time'].iloc[0] / np.timedelta64(1, 'ms'))) // binsize)\n",
    "    \n",
    "    target_bins.append(target_on - move_onset + bins_before_move)\n",
    "    gocue_bins.append(gocue - move_onset + bins_before_move)\n",
    "    move_bins.append(bins_before_move)\n",
    "\n",
    "event_bins.append(torch.tensor(target_bins))\n",
    "event_bins.append(torch.tensor(gocue_bins))\n",
    "event_bins.append(torch.tensor(move_bins))\n",
    "event_bins = torch.stack(event_bins)\n",
    "event_bins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840db6ae-a4b8-4abe-847b-3a0f99eda378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_bins = event_bins.permute(1, 0)\n",
    "\n",
    "event_bins[event_bins < 0] = float('nan')\n",
    "event_bins[event_bins > bins_before_move + bins_after_move] = float('nan')\n",
    "event_bins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b694f84-7c40-444f-b73e-8f5e8461a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0380b0-0668-4f17-a4bd-8b3f5b68422f",
   "metadata": {},
   "source": [
    "### Save data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edf129-12bb-4c82-8581-bf4d16236cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "!mkdir data\n",
    "save_root_path = 'data/'\n",
    "\n",
    "train_data, valid_data, test_data = {}, {}, {}\n",
    "n_trials, seq_len, n_neurons = y.shape\n",
    "n_valid_trials = 574\n",
    "\n",
    "# obs: observations\n",
    "train_data['y_obs'] = torch.Tensor(y[:-n_valid_trials])\n",
    "valid_data['y_obs'] = torch.Tensor(y[-n_valid_trials:-n_valid_trials // 2])\n",
    "test_data['y_obs'] = torch.Tensor(y[-n_valid_trials // 2:])\n",
    "\n",
    "# 'n_bins_enc': Number of time bins used later by in modeling for enconding (default full trial).\n",
    "# 'n_bins_obs': originaly observed trial length (after alignment)\n",
    "# Same for 'n_neurons_obs' and 'n_neurons_enc'.\n",
    "train_data['n_bins_obs'] = valid_data['n_bins_obs'] = test_data['n_bins_obs'] = seq_len\n",
    "train_data['n_bins_enc'] = valid_data['n_bins_enc'] = test_data['n_bins_enc'] = seq_len\n",
    "train_data['n_neurons_obs'] = valid_data['n_neurons_obs'] = test_data['n_neurons_obs'] = n_neurons\n",
    "train_data['n_neurons_enc'] = valid_data['n_neurons_enc'] = test_data['n_neurons_enc'] = n_neurons\n",
    "\n",
    "# Save a 1D array for event bins for each data split, for each trial, for each event.\n",
    "# Note: the o here in event_bins[0] is the session-animal group.\n",
    "for event_id, event in enumerate(['targrt_on_bin', 'go_cue_bin', 'move_onset_bin']):\n",
    "    train_data[event] = torch.Tensor(np.array(event_bins[:-n_valid_trials, event_id]))\n",
    "    valid_data[event] = torch.Tensor(np.array(event_bins[-n_valid_trials:-n_valid_trials // 2, event_id]))\n",
    "    test_data[event] = torch.Tensor(np.array(event_bins[-n_valid_trials // 2:, event_id]))\n",
    "\n",
    "train_data['hand_vel'] = torch.Tensor(np.array(labels[:-n_valid_trials, :, :]))\n",
    "valid_data['hand_vel'] = torch.Tensor(np.array(labels[-n_valid_trials:-n_valid_trials // 2, :, :]))\n",
    "test_data['hand_vel'] = torch.Tensor(np.array(labels[-n_valid_trials // 2:, :, :]))\n",
    "\n",
    "train_data['conds'] = torch.Tensor(np.array(conds[:-n_valid_trials]))\n",
    "valid_data['conds'] = torch.Tensor(np.array(conds[-n_valid_trials:-n_valid_trials // 2]))\n",
    "test_data['conds'] = torch.Tensor(np.array(conds[-n_valid_trials // 2:]))\n",
    "\n",
    "train_data['target_pos'] = target_pos[:-n_valid_trials]\n",
    "valid_data['target_pos'] = target_pos[-n_valid_trials:-n_valid_trials // 2]\n",
    "test_data['target_pos'] = target_pos[-n_valid_trials // 2:]\n",
    "\n",
    "train_data['active_target'] = torch.Tensor(np.array(active_target[:-n_valid_trials]))\n",
    "valid_data['active_target'] = torch.Tensor(np.array(active_target[-n_valid_trials:-n_valid_trials // 2]))\n",
    "test_data['active_target'] = torch.Tensor(np.array(active_target[-n_valid_trials // 2:]))\n",
    "\n",
    "'''\n",
    "for label_id, label in enumerate(label_cols):\n",
    "    train_data[f'{label[0]}_{label[1]}'] = torch.Tensor(np.array(labels[:-n_valid_trials, :, :]))\n",
    "    valid_data[f'{label[0]}_{label[1]}'] = torch.Tensor(np.array(labels[-n_valid_trials:-n_valid_trials // 2, :, :]))\n",
    "    test_data[f'{label[0]}_{label[1]}'] = torch.Tensor(np.array(labels[-n_valid_trials // 2:, :, :]))\n",
    "'''\n",
    "torch.save(train_data, save_root_path + f'data_train_{binsize}ms.pt')\n",
    "torch.save(valid_data, save_root_path + f'data_valid_{binsize}ms.pt')\n",
    "torch.save(test_data, save_root_path + f'data_test_{binsize}ms.pt')\n",
    "\n",
    "print('Data splits (train/valid/test) saved into the \"data\" folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75946d9-ad86-4eeb-ac8c-2997a68d826a",
   "metadata": {},
   "source": [
    "## Load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942e4f1-d781-4332-aced-53464f768240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data_{split}_{bin_sz_ms}ms.pt'\n",
    "train_data = torch.load(data_path.format(split='train', bin_sz_ms=cfg.bin_sz_ms))\n",
    "val_data = torch.load(data_path.format(split='valid', bin_sz_ms=cfg.bin_sz_ms))\n",
    "test_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "\n",
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_valid_obs = val_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_valid = val_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "\n",
    "# Data dimensions\n",
    "n_train_trials, n_time_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_valid_trials = y_valid_obs.shape[0]\n",
    "n_test_trials = y_test_obs.shape[0]\n",
    "n_time_bins_enc = train_data['n_time_bins_enc']\n",
    "\n",
    "batch_sz_train = list(y_train_obs.shape)[:-1]\n",
    "batch_sz_valid = list(y_valid_obs.shape)[:-1]\n",
    "batch_sz_test = list(y_test_obs.shape)[:-1]\n",
    "\n",
    "print(\"# training trials: {0}\".format(n_train_trials))\n",
    "print(\"# validation trials: {0}\".format(n_valid_trials))\n",
    "print(\"# testing trials: {0}\".format(n_test_trials))\n",
    "print(\"# neurons: {0}\".format(n_neurons_obs))\n",
    "print(\"# time bins: {0}\".format(n_time_bins))\n",
    "print(\"# time bins used for forcasting: {0}\".format(cfg.n_bins_bhv))\n",
    "print(\"# predicted time bins: {0}\".format(n_time_bins - cfg.n_bins_bhv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bd434-4093-4914-a044-f66b5085b215",
   "metadata": {},
   "source": [
    "### Reach variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eb108-ef15-4d8a-af22-c71b9f5acd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conds_ids, cond_counts = torch.unique(conds, return_counts=True)\n",
    "cond_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcca684-153c-492f-9112-02a822463106",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cs, top_ids = torch.topk(cond_counts, 5)\n",
    "top_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b287845-040e-46ca-bdb9-532fe06758c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_info['num_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccece584-c86b-47ce-b5f2-3d37d7432624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trial-averged 108 reach conditions\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.suptitle('Aligned trials (same length)')\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "# Loop over conditions and compute average trajectory\n",
    "for cond_idx, cond in enumerate([cond for cond in trial_info.set_index(['trial_type', 'trial_version']).index.unique().tolist() if not any(math.isnan(x) for x in cond)]):\n",
    "    # Find trials in condition\n",
    "    mask = np.all(dataset.trial_info[['trial_type', 'trial_version']] == cond, axis=1)\n",
    "    trial_d = dataset.make_trial_data(align_field='move_onset_time', align_range=(-240, 660), ignored_trials=(~mask))\n",
    "    traj = trial_d.groupby('align_time')[[('hand_pos', 'x'), ('hand_pos', 'y')]].mean().to_numpy()\n",
    "    # Determine reach angle for color\n",
    "    reach_angle = np.arctan2(*trial_info[mask].target_pos.iloc[0][int(trial_info[mask].active_target.iloc[0])][::-1])\n",
    "    # Plot reach\n",
    "    ax.plot(traj[:, 0], traj[:, 1], linewidth=0.7, color=plt.cm.hsv(reach_angle / (2*np.pi) + 0.5))\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.savefig('trial_averged_reaches_108')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519c75-31f4-4d01-8ee1-71c79ac2d1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data = y\n",
    "y_vel = labels\n",
    "y_conds = conds\n",
    "y_t_pos = target_pos\n",
    "act_t = active_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cda55-1ff4-4bb5-ba0f-d120ae220309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cond_trials(y_vel, y_conds):\n",
    "    psth = np.zeros((len(conds_ids), y_vel.shape[1], y_vel.shape[2]))\n",
    "\n",
    "    for cond in conds_ids:\n",
    "        mask = y_conds == cond\n",
    "        psth[cond, :, :] = y_vel[mask, :, :].mean(axis=0)\n",
    "    \n",
    "    return psth\n",
    "\n",
    "def calc_var_to_mean_ratio(psth):\n",
    "    v_m_ratio =  np.sum((psth.var(axis=0)) / (psth.mean(axis=0)), axis=0)\n",
    "    \n",
    "    return(np.nan_to_num(v_m_ratio, nan=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a0ed-2aeb-4f5d-b93a-d9179604c4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psth = get_cond_trials(y_vel, y_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a66bf-fddb-4b4b-9f1c-f2cb60bb6d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e67f85-8bfb-4b9e-b8f5-309b0fb4e444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vmr = calc_var_to_mean_ratio(psth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e899a1-110b-4066-b780-68e6a1824050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c08d0b-7d3d-463b-aff6-7965403b482a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psth[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a8a55-4301-4d7d-865f-c5ad89124d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the variance for each tensor along the specified dimension\n",
    "var = [t.var(axis=0).mean().item() for t in psth[0, :, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cd4b7-4a50-440c-ac76-09afb0b65f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57ee43-09b4-46c1-a2d2-bb546ef2aa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(var).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbb7d5-e54e-425c-a01e-41be7f258052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psth[0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bf3c8-902b-4c48-989a-eaf674f19f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sort the tensors based on the calculated variances\n",
    "sorted_tensors = [tensor for _, tensor in sorted(zip(variances, tensors), key=lambda x: x[0])]\n",
    "\n",
    "# Output the sorted tensors\n",
    "for i, tensor in enumerate(sorted_tensors):\n",
    "    print(f\"Tensor {i+1}:\\n{tensor}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e9576-853c-41d0-8a6c-ffe13711c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "psth[0, :, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfads2",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
